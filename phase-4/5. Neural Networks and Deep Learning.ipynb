{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "33f80bd9",
      "metadata": {},
      "source": [
        "# Neural Networks and Deep Learning\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Introduction to Neural Networks\n",
        "\n",
        "### What is a Neural Network?\n",
        "\n",
        "A neural network is a machine learning model designed to mimic how our brains learn and process information. It is made up of layers of “neurons” that learn to recognize patterns.\n",
        "\n",
        "**Anecdote**: Imagine you're teaching a toddler to recognize cats. You show many pictures of cats, and the toddler slowly begins to learn what a cat looks like. A neural network learns in a similar way-from examples.\n",
        "\n",
        "### Structure of a Neural Network:\n",
        "\n",
        "* **Input Layer**: Where data enters the model (like a person's height or age).\n",
        "* **Hidden Layers**: These do the actual learning by detecting patterns.\n",
        "* **Output Layer**: Gives the final prediction.\n",
        "\n",
        "**Example**:\n",
        "\n",
        "```\n",
        "Input  ---> Hidden Layer ---> Output\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Neural Networks in Pipelines\n",
        "\n",
        "We use **pipelines** to keep our machine learning workflow clean and organized.\n",
        "\n",
        "### Example with Scikit-learn and Keras:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "5036bc11",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4443ea54",
      "metadata": {},
      "source": [
        "This sets up a pipeline where data is first scaled, then passed into a neural network model.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Gradient Descent\n",
        "\n",
        "### What Is Gradient Descent?\n",
        "\n",
        "It’s the method neural networks use to learn-by gradually adjusting weights to reduce prediction errors.\n",
        "\n",
        "**Analogy**: Think of trying to walk downhill blindfolded. You feel around with your foot, find the steepest slope, and take a small step down. That’s how Gradient Descent works.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. The Gradient in Gradient Descent\n",
        "\n",
        "### Formula:\n",
        "\n",
        "$$\n",
        "w = w - \\alpha \\frac{\\partial J}{\\partial w}\n",
        "$$\n",
        "\n",
        "* **w** = current weight\n",
        "* **α** = learning rate (step size)\n",
        "* **∂J/∂w** = gradient (slope of the loss function)\n",
        "\n",
        "### Python Code Equivalent:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "b39aa4dc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.998\n"
          ]
        }
      ],
      "source": [
        "# Initial weight\n",
        "w = 5\n",
        "\n",
        "# Suppose gradient = 0.2 and learning_rate = 0.01\n",
        "gradient = 0.2\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Update the weight\n",
        "w = w - learning_rate * gradient\n",
        "print(w)  # Output: 4.998"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f285cff3",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5. Scalars, Vectors, Matrices, and Tensors\n",
        "\n",
        "* **Scalar** = Single value (e.g. 7)\n",
        "* **Vector** = 1D list (e.g. \\[7, 2])\n",
        "* **Matrix** = 2D grid (e.g. \\[\\[1, 2], \\[3, 4]])\n",
        "* **Tensor** = N-dimensional array used in deep learning\n",
        "\n",
        "Tensors help move data through a neural network.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Introduction to Keras\n",
        "\n",
        "Keras is a beginner-friendly library for building neural networks.\n",
        "\n",
        "### Example Model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "0616ddde",
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(16, activation='relu', input_shape=(10,)))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79ae28cb",
      "metadata": {},
      "source": [
        "### Explanation:\n",
        "\n",
        "* `Sequential()` = A stack of layers\n",
        "* `Dense(16)` = 16 neurons\n",
        "* `activation='relu'` = Adds non-linearity\n",
        "* `input_shape=(10,)` = 10 input features\n",
        "* `sigmoid` = Good for binary output (0 or 1)\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Tuning Neural Networks with Normalization\n",
        "\n",
        "### Why Normalize?\n",
        "\n",
        "Features like age (1-100) and income (thousands) can confuse the model if not scaled.\n",
        "\n",
        "### Example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "b9b58fef",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-1.41421356 -1.41421356 -1.41421356]\n",
            " [-0.70710678 -0.70710678 -0.70710678]\n",
            " [ 0.          0.          0.        ]\n",
            " [ 0.70710678  0.70710678  0.70710678]\n",
            " [ 1.41421356  1.41421356  1.41421356]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Example: create some sample data\n",
        "# shape: 5 samples × 3 features\n",
        "X = np.array([\n",
        "    [1.0, 200.0, 0.5],\n",
        "    [2.0, 300.0, 0.75],\n",
        "    [3.0, 400.0, 1.0],\n",
        "    [4.0, 500.0, 1.25],\n",
        "    [5.0, 600.0, 1.5]\n",
        "])\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(X_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f9b0265",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 8. Tuning with Evaluation\n",
        "\n",
        "### Compile and Fit the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "95507801",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 0.5125 - loss: 0.7883 - val_accuracy: 0.4000 - val_loss: 0.9197\n",
            "Epoch 2/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5125 - loss: 0.7804 - val_accuracy: 0.4000 - val_loss: 0.9091\n",
            "Epoch 3/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5125 - loss: 0.7745 - val_accuracy: 0.4000 - val_loss: 0.8986\n",
            "Epoch 4/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5125 - loss: 0.7681 - val_accuracy: 0.4000 - val_loss: 0.8885\n",
            "Epoch 5/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5125 - loss: 0.7619 - val_accuracy: 0.4000 - val_loss: 0.8793\n",
            "Epoch 6/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5125 - loss: 0.7565 - val_accuracy: 0.4000 - val_loss: 0.8705\n",
            "Epoch 7/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5125 - loss: 0.7506 - val_accuracy: 0.4000 - val_loss: 0.8623\n",
            "Epoch 8/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5125 - loss: 0.7453 - val_accuracy: 0.4000 - val_loss: 0.8541\n",
            "Epoch 9/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5125 - loss: 0.7407 - val_accuracy: 0.4000 - val_loss: 0.8461\n",
            "Epoch 10/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5250 - loss: 0.7363 - val_accuracy: 0.4000 - val_loss: 0.8383\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x22572c8c740>"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create dummy binary classification data\n",
        "X = np.random.rand(100, 5)  # 100 samples, 5 features\n",
        "y = np.random.randint(0, 2, size=(100, 1))  # binary labels\n",
        "\n",
        "# Split into train and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define model\n",
        "model = Sequential([\n",
        "    Dense(10, activation='relu', input_shape=(5,)),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bab12cec",
      "metadata": {},
      "source": [
        "* `optimizer='adam'` = Smart way to adjust weights\n",
        "* `loss='binary_crossentropy'` = Good for binary classification\n",
        "* `validation_data` = See performance on new (unseen) data\n",
        "\n",
        "---\n",
        "\n",
        "## 9. Tuning with Regularization\n",
        "\n",
        "### Dropout\n",
        "\n",
        "Drops some neurons randomly during training to prevent overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "4b418667",
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.layers import Dropout\n",
        "model.add(Dropout(0.3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "468b88e2",
      "metadata": {},
      "source": [
        "### L1/L2 Regularization\n",
        "\n",
        "Adds a penalty to large weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "a2d654f3",
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.regularizers import l2\n",
        "model.add(Dense(64, kernel_regularizer=l2(0.01)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94484434",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. Build a simple neural network using Keras.\n",
        "2. Normalize your dataset and compare model performance.\n",
        "3. Try using Dropout and L2 regularization. What changes?\n",
        "4. Implement a basic Gradient Descent loop in Python.\n",
        "5. Use `model.evaluate()` on your test data. What metric does best?\n",
        "\n",
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "* Neural Networks are inspired by the brain and learn from data.\n",
        "* Gradient Descent adjusts weights to reduce error.\n",
        "* Keras simplifies model creation.\n",
        "* Normalization, Evaluation, and Regularization improve model performance.\n",
        "* Tensors are how data moves through the network.\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
