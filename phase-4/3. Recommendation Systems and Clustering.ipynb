{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "076ab20b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Recommendation Systems and Clustering Techniques – Beginner-Friendly Guide\n",
    "\n",
    "---\n",
    "\n",
    "## Part 1: Recommendation Systems\n",
    "\n",
    "### What is a Recommendation System?\n",
    "\n",
    "Imagine you walk into a bookstore and the staff says:\n",
    "“You liked that mystery novel last week. Here’s another one people like you enjoyed.”\n",
    "\n",
    "That’s exactly what a recommendation system does:\n",
    "\n",
    "* **Content-Based Filtering**: Suggests items based on what *you* liked.\n",
    "* **Collaborative Filtering**: Suggests items based on what *others like you* liked.\n",
    "\n",
    "---\n",
    "\n",
    "### Collaborative Filtering with SVD (Singular Value Decomposition)\n",
    "\n",
    "Let’s say you have a matrix of users vs. items (like ratings of movies). Most of the cells are empty because not everyone has rated everything.\n",
    "\n",
    "SVD helps by breaking this large sparse matrix into **three smaller matrices** that capture hidden patterns.\n",
    "\n",
    "$$\n",
    "R \\approx U \\cdot \\Sigma \\cdot V^T\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $R$ = Original ratings matrix\n",
    "* $U$ = User preference matrix\n",
    "* $\\Sigma$ = Diagonal matrix showing strength of hidden features\n",
    "* $V^T$ = Item feature matrix\n",
    "\n",
    "SVD helps predict missing ratings and recommend new items.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7063d883",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import train_test_split, cross_validate\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from surprise import KNNBasic, Dataset, SVD, Dataset, Reader,  accuracy\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7922ca",
   "metadata": {},
   "source": [
    "#### Example (Using Surprise Library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15e991ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9418  0.9374  0.9423  0.9283  0.9404  0.9380  0.0052  \n",
      "MAE (testset)     0.7431  0.7394  0.7400  0.7303  0.7418  0.7389  0.0045  \n",
      "Fit time          1.15    1.23    1.19    1.19    1.15    1.18    0.03    \n",
      "Test time         0.17    0.32    0.17    0.17    0.17    0.20    0.06    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.94176471, 0.93740613, 0.94231118, 0.92829165, 0.9404458 ]),\n",
       " 'test_mae': array([0.74310684, 0.73942985, 0.7400365 , 0.7303213 , 0.74181447]),\n",
       " 'fit_time': (1.1500041484832764,\n",
       "  1.2330026626586914,\n",
       "  1.1901075839996338,\n",
       "  1.1874644756317139,\n",
       "  1.1499977111816406),\n",
       " 'test_time': (0.16999483108520508,\n",
       "  0.324998140335083,\n",
       "  0.17299485206604004,\n",
       "  0.166001558303833,\n",
       "  0.16500234603881836)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load built-in dataset\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "# Use SVD model\n",
    "model = SVD()\n",
    "\n",
    "# Evaluate using cross-validation\n",
    "cross_validate(model, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6baf850",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Matrix Factorization with ALS (Alternating Least Squares)\n",
    "\n",
    "ALS is a scalable matrix factorization technique where the algorithm alternates between:\n",
    "\n",
    "* Fixing user vectors and solving item vectors\n",
    "* Then fixing item vectors and solving user vectors\n",
    "\n",
    "This \"back-and-forth\" continues until both are optimized. ALS is widely used in tools like Apache Spark for large datasets.\n",
    "\n",
    "---\n",
    "\n",
    "### Implementing Recommendation Engines with Surprise\n",
    "\n",
    "The `Surprise` library makes it easy to build recommender systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7e341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Use basic k-nearest neighbor collaborative filtering\n",
    "model = KNNBasic()\n",
    "model.fit(trainset)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "predictions = model.test(testset)\n",
    "print(\"RMSE:\", accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99208b9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Clustering\n",
    "\n",
    "### What is Clustering?\n",
    "\n",
    "Imagine you have a drawer full of mixed socks. You don’t know the brands, but you sort them by color and size into groups. That’s clustering.\n",
    "\n",
    "Clustering is about finding hidden groups in data without using labels.\n",
    "\n",
    "---\n",
    "\n",
    "### KMeans Clustering\n",
    "\n",
    "KMeans divides your data into **K groups** based on similarity.\n",
    "\n",
    "#### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4875dd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset\n",
    "X = np.array([[1,2],[1,4],[1,0],[10,2],[10,4],[10,0]])\n",
    "\n",
    "# Fit KMeans\n",
    "model = KMeans(n_clusters=2)\n",
    "model.fit(X)\n",
    "\n",
    "# Plot clusters\n",
    "plt.scatter(X[:, 0], X[:, 1], c=model.labels_, cmap='viridis')\n",
    "plt.title(\"KMeans Clustering\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef6f9ec",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Hierarchical Agglomerative Clustering\n",
    "\n",
    "This approach builds clusters from the bottom up:\n",
    "\n",
    "* Start with each data point as its own cluster\n",
    "* Merge the two closest clusters\n",
    "* Repeat until only a few clusters remain\n",
    "\n",
    "#### Dendrogram Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cddc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = linkage(X, method='ward')\n",
    "dendrogram(Z)\n",
    "plt.title(\"Hierarchical Dendrogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b24635",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Problems in Clustering\n",
    "\n",
    "* Choosing the wrong number of clusters (try the Elbow Method)\n",
    "* Clusters with very different shapes or densities\n",
    "* Outliers pulling centroids away from real centers\n",
    "\n",
    "---\n",
    "\n",
    "## Semi-Supervised Learning and Look-Alike Models\n",
    "\n",
    "Semi-supervised learning combines a small amount of labeled data with a large amount of unlabeled data.\n",
    "\n",
    "**Example Use Case**:\n",
    "You have data on customers who purchased a product and many who didn’t. You train on the known buyers, then find “look-alike” customers who share similar behavior patterns.\n",
    "\n",
    "---\n",
    "\n",
    "## Principal Component Analysis (PCA) in scikit-learn\n",
    "\n",
    "PCA simplifies high-dimensional data by reducing it to fewer components, while keeping the most important information.\n",
    "\n",
    "#### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b0cfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_reduced = pca.fit_transform(X)\n",
    "\n",
    "# Visualize\n",
    "plt.scatter(X_reduced[:, 0], X_reduced[:, 1])\n",
    "plt.title(\"PCA Result\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b188bbbf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Market Segmentation with Clustering\n",
    "\n",
    "Market segmentation means dividing your customer base into smaller groups based on behavior or traits:\n",
    "\n",
    "* Age\n",
    "* Income\n",
    "* Shopping habits\n",
    "\n",
    "**Example**:\n",
    "\n",
    "* Cluster customers based on purchase behavior.\n",
    "* Send targeted promotions to each group.\n",
    "\n",
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. Use KMeans to cluster the Iris dataset and visualize the results.\n",
    "2. Apply PCA on a high-dimensional dataset and reduce to 2D for visualization.\n",
    "3. Build a simple recommendation engine using the `Surprise` library.\n",
    "4. Plot a dendrogram of customer similarity using hierarchical clustering.\n",
    "5. Try out both SVD and KNN on a small ratings dataset and compare RMSE.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "* Recommendation systems use either what you like (content-based) or what others like (collaborative filtering).\n",
    "* SVD and ALS help fill in missing user-item data.\n",
    "* Clustering helps us discover hidden patterns without labels.\n",
    "* PCA reduces dimensionality for easier visualization and modeling.\n",
    "* Clustering is especially powerful in market segmentation and personalization.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
